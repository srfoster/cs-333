id: "ch2-fibonacci-call-tree-optimizations-and-analysis"
type: "short-answer"
chapter: 2
question: |
  **Write three implementations of the Fibonacci function: (1) naive recursive, (2) memoized recursive, and (3) iterative bottom-up.**
  
  **Level 0** Discuss why the naive Fibonacci recursion is a classic example of algorithmic inefficiency and why this problem is fundamental to understanding dynamic programming. Explain the broader significance of memoization as an optimization technique.
  
  **Level 1** For naive recursion: Draw or describe the call tree for fib(5) and identify repeated computations. For memoization: Explain how caching eliminates redundant calls. For iteration: Describe the bottom-up approach. Provide pseudocode for all three versions and step through them with small examples.
  
  **Level 2** Implement all three versions in a language of your choice.
  
  **Level 3** Analyze the time and space complexity of each approach:
  - Write the recurrence relation T(n) for naive recursion and explain why it leads to O(2ⁿ) time
  - Explain how memoization reduces complexity to O(n) time with O(n) space
  - Show that iteration achieves O(n) time with O(1) space
  - Discuss the trade-offs between these approaches and when each is appropriate
answer: |
  **Complexity Analysis:**
  
  **1. Naive Recursion:**
  - Time: O(2ⁿ) - Recurrence T(n) = T(n-1) + T(n-2) + O(1) grows exponentially
  - Space: O(n) - Maximum call stack depth
  - Problem: Recomputes same values exponentially many times (fib(3) computed 2 times, fib(2) computed 3 times in fib(5))
  
  **2. Memoized Recursion:**
  - Time: O(n) - Each fib(i) computed exactly once, then cached
  - Space: O(n) - Cache storage + O(n) call stack
  - Benefit: Elegant code with dramatic performance improvement through caching
  
  **3. Iterative Bottom-Up:**
  - Time: O(n) - Single loop computing values in order
  - Space: O(1) - Only need two variables (previous two values)
  - Benefit: Most efficient approach, no recursion overhead
  
  **Key Insights:**
  - Call tree visualization shows why naive approach is O(2ⁿ): full binary tree of height n has ~2ⁿ nodes
  - Memoization transforms overlapping subproblems into single computations
  - This pattern (naive → memoized → bottom-up) applies to all dynamic programming problems
  - Choice depends on: code clarity vs space efficiency vs performance requirements
topics:
  - "Recursion"
  - "Dynamic Programming"
  - "Memoization"
  - "Call Trees"
  - "Recurrence Relations"
  - "Algorithm Optimization"
example_videos:
  - "https://youtu.be/Hfwcsbtg_7U"
  - "https://www.youtube.com/watch?v=M-NeO_9BU_A"
  - "https://www.youtube.com/watch?v=5dRGRueKU3M"
  - "https://www.youtube.com/watch?v=P8Xa2BitN3I"
  - "https://www.youtube.com/watch?v=hbveibMDHfg"
  - "https://www.youtube.com/watch?v=e0CAbRVYAWg"
